# TransparentCalifornia Data Scraper and Shiny App

## Project Overview

This project is designed to scrape compensation data for public employees from [Transparent California](https://transparentcalifornia.com/). The scraped data is then processed, cleaned, and enriched (e.g., by attempting to generate email addresses). The primary output is an RDS data file (`output/transparentcalifornia-outreach.rds`) which serves as the data source for an interactive R Shiny application.

The Shiny app (`app.R`) allows users to explore this data, offering features to filter by agency, year, and job title, and to download the filtered dataset. The project includes automated GitHub Actions workflows to keep the data updated and to facilitate the deployment of the Shiny app.

A live version of the Shiny App can be found here: [https://matthanc.shinyapps.io/transparentcaliforniaoutreach/](https://matthanc.shinyapps.io/transparentcaliforniaoutreach/) (Note: This link is from the original README and may or may not reflect the current deployment of this specific repository instance).

## File Descriptions

Here's a breakdown of the key files and directories in this project:

*   **`transparentcalifornia.R`**:
    *   This R script is the core data scraping and processing engine.
    *   It navigates the Transparent California website to gather salary and benefits data for various public agencies.
    *   It performs data cleaning, including removing special characters, handling missing values, and standardizing some fields.
    *   It enriches the data by attempting to parse employee names into components (first, middle, last) using the `humaniformat` package.
    *   It attempts to generate potential email addresses based on common patterns and agency-specific domain information found in `email.csv`.
    *   It filters organizations based on distance from a specified central organization (default: "San Francisco") using geographical coordinates from `coords.csv`.
    *   The script includes robust error handling for web requests and data processing steps.
    *   It performs data validation checks (data types, email formats, missing values) before saving the output.
    *   The final processed data is saved as `output/transparentcalifornia-outreach.rds`.

*   **`app.R`**:
    *   This R script defines the user interface (UI) and server logic for the Shiny web application.
    *   It loads the processed data from `output/transparentcalifornia-outreach.rds`.
    *   It provides interactive filters for 'Agency', 'Year', and 'Job Title'.
    *   It displays the filtered data in a searchable and sortable table using the `DT` package.
    *   It includes a feature to download the filtered data as a CSV file.

*   **`output/transparentcalifornia-outreach.rds`**:
    *   This is the main data file generated by the `transparentcalifornia.R` script.
    *   It contains the scraped, processed, and cleaned employee compensation data in an R-specific RDS format, which is efficient for R to read and write.
    *   This file is used directly by `app.R` to populate the Shiny application.

*   **`.github/workflows/`**: This directory contains GitHub Actions workflow configurations.
    *   **`setup-r-env.yml`**: This is a reusable workflow designed to set up an R environment. It performs steps like checking out the repository, setting up a specific R version, installing system dependencies required by R packages, installing specified R packages (including Bioconductor's `Biobase`), and can optionally run a provided R script, commit changes to a new branch, create a pull request, and deploy a Shiny app. It's parameterized to be flexible for different calling workflows.
    *   **`run-r-script.yml`**: This workflow automates the process of updating the data and deploying the Shiny app.
        *   It is scheduled to run quarterly.
        *   It calls `setup-r-env.yml` to:
            *   Run the `transparentcalifornia.R` scraper script.
            *   If the data changes, commit the updated `output/transparentcalifornia-outreach.rds` to a new branch and create a pull request against the `main` branch.
            *   Deploy the Shiny application using the data currently on the `main` branch.
    *   **`deploy.yml`**: This workflow allows for manual deployment of the Shiny application.
        *   It calls `setup-r-env.yml` to:
            *   Set up the R environment and install necessary packages for deployment.
            *   Deploy the Shiny application (using `app.R` and `output/transparentcalifornia-outreach.rds` from the `main` branch) to shinyapps.io.

*   **`coords.csv`**:
    *   A CSV file containing a list of California public agencies and their approximate geographical coordinates (latitude and longitude).
    *   Used by `transparentcalifornia.R` to calculate distances and filter organizations based on proximity to a specified central organization.

*   **`email.csv`**:
    *   A CSV file that maps public agencies to their likely email domain suffixes and common email address structures (e.g., "first.last@domain.com", "flast@domain.com").
    *   Used by `transparentcalifornia.R` to help generate potential email addresses for employees.

## Data Sources

*   **Primary Data**: The core employee compensation data is scraped from [Transparent California](https://transparentcalifornia.com/).
*   **Supporting Data**:
    *   Agency coordinates: `coords.csv` (presumably manually compiled or sourced elsewhere).
    *   Email patterns: `email.csv` (presumably manually compiled or sourced elsewhere).

## Setup and Usage

### Prerequisites

*   **R**: You'll need R installed on your system. You can download it from [CRAN](https://cran.r-project.org/).
*   **R Packages**: Both the scraper and the Shiny app require several R packages. These are listed at the top of `transparentcalifornia.R` and `app.R` respectively. Key packages include `rvest`, `dplyr`, `purrr`, `stringr`, `readr`, `shiny`, `DT`, etc.
    *   The `setup-r-env.yml` workflow details the installation of these packages, including system dependencies often required on Linux systems (e.g., `libcurl4-openssl-dev`, `libssl-dev`, `libxml2-dev`).

### Running the Scraper (`transparentcalifornia.R`)

1.  **Set Working Directory**: Ensure your R session's working directory is the root of this project.
2.  **Install Packages**: If you haven't already, install the required packages. You can do this by running the `install.packages(...)` commands found at the beginning of the script or via the GitHub Actions setup.
    ```R
    # Example for some core packages (see script for full list)
    # install.packages(c("rvest", "dplyr", "purrr", "readr", "humaniformat", "geosphere"))
    # if (!requireNamespace("BiocManager", quietly = TRUE)) install.packages("BiocManager")
    # BiocManager::install("Biobase")
    ```
3.  **Run the Script**:
    ```bash
    Rscript transparentcalifornia.R
    ```
    Or, you can run it line-by-line or source it within an R environment (like RStudio).
4.  **Output**: The script will create (or overwrite) `output/transparentcalifornia-outreach.rds`. It also prints progress messages and any warnings to the console.
    *   By default, the script uses "San Francisco" as the central organization and a large distance filter (9999 miles) to include most Californian agencies. These can be changed by modifying the parameters in the `tcfilter()` call within the script if needed for local runs.

### Running the Shiny App (`app.R`)

1.  **Data File**: Ensure the `output/transparentcalifornia-outreach.rds` file exists (generated by running `transparentcalifornia.R`).
2.  **Set Working Directory**: Your R session's working directory should be the root of this project, where `app.R` and the `output` directory are located.
3.  **Install Packages**: Install Shiny and other required packages listed in `app.R`.
    ```R
    # Example for some core packages (see script for full list)
    # install.packages(c("shiny", "tidyverse", "shinythemes", "DT", "shinyWidgets", "scales"))
    ```
4.  **Run the App**:
    You can run the app in several ways:
    *   Using `shiny::runApp()`:
        ```R
        # In an R console
        shiny::runApp("app.R")
        ```
    *   From RStudio: Open `app.R` and click the "Run App" button.
5.  **Usage**: The app will open in your default web browser, allowing you to filter and explore the data.

## Automated Workflows (GitHub Actions)

This project utilizes GitHub Actions to automate data updates and application deployment.

*   **Scheduled Data Scraping and PR Creation (`run-r-script.yml`)**:
    *   This workflow runs on a schedule (quarterly).
    *   It executes the `transparentcalifornia.R` script to scrape the latest data.
    *   If the data file (`output/transparentcalifornia-outreach.rds`) changes, the workflow does *not* commit directly to the `main` branch. Instead, it:
        1.  Creates a new branch (e.g., `data-update/YYYYMMDDHHMMSS`).
        2.  Commits the updated data to this new branch.
        3.  Pushes the new branch to the repository.
        4.  Opens a Pull Request (PR) against the `main` branch. This allows for review of the data changes before they are merged.
    *   This workflow also handles the deployment of the Shiny app to shinyapps.io, using the data currently available on the `main` branch. This means if a data update PR is pending, the app deploys with the *existing* main branch data.

*   **Manual Shiny App Deployment (`deploy.yml`)**:
    *   This workflow allows for manual triggering of the Shiny app deployment.
    *   It uses the current state of `app.R` and `output/transparentcalifornia-outreach.rds` from the `main` branch to deploy to shinyapps.io.

*   **Reusable Setup (`setup-r-env.yml`)**:
    *   Both of the above workflows use this reusable workflow.
    *   `setup-r-env.yml` is responsible for setting up the R environment, installing all necessary system and R packages, running the scraper script, handling git operations (like PR creation), and deploying the Shiny app, all based on parameters passed by the calling workflow. This centralizes the operational logic.

## Contribution Guidelines

Currently, this project is maintained by a small team. However, if you have suggestions or find issues, please feel free to:
*   Open an issue on the GitHub repository to report bugs or suggest features.
*   Fork the repository and propose changes via a pull request if you'd like to contribute directly to the code.

## License

(Assuming MIT License - if different, this should be updated. The original README did not specify a license. A `LICENSE` file should ideally be present in the repository.)

This project is licensed under the MIT License. See the `LICENSE` file for details.
(If no LICENSE file exists, consider adding one. For now, this is a placeholder.)
